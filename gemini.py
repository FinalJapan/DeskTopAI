import sounddevice as sd
import soundfile as sf
import numpy as np
import os
import tempfile
import requests
import keyboard
import threading
import time
import concurrent.futures
from faster_whisper import WhisperModel
from dotenv import load_dotenv
from pathlib import Path
import json
import google.generativeai as palm
gemini_model = palm.GenerativeModel('models/gemini-2.0-flash')

load_dotenv()

# ============================
# ğŸŒ Gemini API åˆæœŸåŒ–
# ============================
palm.configure(api_key=os.getenv("GOOGLE_API_KEY"))


# ============================
# ğŸ§  ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨˜æ†¶ï¼ˆèª­ã¿æ›¸ãï¼‰
# ============================
MEMORY_FILE = Path("memory.json")

def load_persona():
    if not MEMORY_FILE.exists():
        return ""
    with open(MEMORY_FILE, "r", encoding="utf-8") as f:
        memory_data = json.load(f)
    memory_lines = [f"{key}ï¼š{value}" for key, value in memory_data.items()]
    return "\n".join(memory_lines)

def save_persona(new_data):
    if MEMORY_FILE.exists():
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            memory_data = json.load(f)
    else:
        memory_data = {}
    memory_data.update(new_data)
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory_data, f, indent=2, ensure_ascii=False)

def handle_memory_command(user_text):
    if user_text.startswith("ã“ã‚Œã¯è¦šãˆã¦"):
        try:
            info = user_text.replace("ã“ã‚Œã¯è¦šãˆã¦", "").strip()
            if "ã¯" in info:
                key, value = info.split("ã¯", 1)
                key = key.strip()
                value = value.strip()
                save_persona({key: value})
                return f"ã†ã‚“ã€{key}ã¯ã€Œ{value}ã€ã£ã¦è¦šãˆãŸã‚ˆï¼"
            else:
                return "ãªã‚“ã¦è¦šãˆã‚Œã°ã„ã„ã‹åˆ†ã‹ã‚“ãªã‹ã£ãŸâ€¦"
        except Exception as e:
            return f"âš ï¸ è¨˜æ†¶ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"

    elif user_text.startswith("ã“ã‚Œã¯å¿˜ã‚Œã¦"):
        try:
            key = user_text.replace("ã“ã‚Œã¯å¿˜ã‚Œã¦", "").strip()
            if MEMORY_FILE.exists():
                with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                    memory_data = json.load(f)
                if key in memory_data:
                    del memory_data[key]
                    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
                        json.dump(memory_data, f, indent=2, ensure_ascii=False)
                    return f"ã€Œ{key}ã€ã®è¨˜æ†¶ã¯æ¶ˆã—ãŸã‚ˆã€‚"
                else:
                    return "ãã‚“ãªè¨˜æ†¶ã¯ãªã‹ã£ãŸã¿ãŸã„ã€‚"
        except Exception as e:
            return f"âš ï¸ è¨˜æ†¶å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}"
    return None

# ============================
# ğŸ¤– Geminiå¿œç­”ç”Ÿæˆ
# ============================
def get_gemini_reply(user_input):
    memory_context = load_persona()

    prompt = (
        "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
        "ãƒ—ãƒ­ã¨ã—ã¦ã®è‡ªè¦šã‚’ã‚‚ã£ã¦ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚\n"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«çš„ç¢ºã«ç­”ãˆãŸã‚Šã€å›°ã£ã¦ã„ãã†ãªäº‹æŸ„ã«ç©æ¥µçš„ã«æ‰‹åŠ©ã‘ã™ã‚‹ã€‚\n"
        "æ•°å­—ã§ç®‡æ¡æ›¸ãã§èª¬æ˜ã¯ã—ãªã„ã€‚å£èª¿ã¯å¥³ã®å­ã§ã€æ˜ã‚‹ãçŸ¥çš„ã«ã€‚\n"
        "æ•¬èªã¯ä½¿ã‚ãšã«ã‚­ãƒŸã¨è©±ã™å£èª¿ã§è¿”ã—ã¦ã­ã€‚\n\n"
    )

    if memory_context:
        prompt += f"ã“ã‚Œã¯è¦šãˆã¦ãŠãã¹ããƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã§ã™:\n{memory_context}\n\n"

    prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ:"

    try:
        generation_config = {
            "temperature": 0.7,
            "max_output_tokens": 300
        }
        response = gemini_model.generate_content( # ã“ã“ã‚’ä¿®æ­£
            contents=prompt,
            generation_config=generation_config
        )
        reply = response.text
        return reply.strip() if reply else "âš ï¸ å¿œç­”ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        return f"âš ï¸ å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# ============================
# ğŸ™ï¸ Whisperã§éŸ³å£°èªè­˜
# ============================
model = WhisperModel("medium", device="cuda", compute_type="float16")

def transcribe_audio(file_path):
    segments, _ = model.transcribe(file_path)
    result = ""
    for segment in segments:
        result += segment.text + " "
    return result.strip()

# ============================
# ğŸ—£ï¸ éŸ³å£°åˆæˆï¼ˆAIVISé€£æºï¼‰
# ============================
def synthesize_voice(text, speaker=1325133120, speed=1.2, volume=0.3):
    try:
        query = requests.post(
            "http://127.0.0.1:10101/audio_query",
            params={"text": text, "speaker": speaker}
        ).json()

        query["speedScale"] = speed
        query["volumeScale"] = volume

        audio = requests.post(
            "http://127.0.0.1:10101/synthesis",
            params={"speaker": speaker},
            json=query
        )

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio.content)
            return tmp.name
    except Exception as e:
        print(f"âš ï¸ AIVISéŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ============================
# ğŸ”Š éŸ³å£°å†ç”Ÿ
# ============================
def play_voice(file_path):
    if file_path and os.path.exists(file_path):
        try:
            data, fs = sf.read(file_path)
            sd.play(data, fs)
            sd.wait()
        except Exception as e:
            print(f"âš ï¸ éŸ³å£°å†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        print("âš ï¸ å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")


# ============================
# ğŸ” Geminiå¿œç­”ã¨éŸ³å£°å‡ºåŠ›çµ±åˆå‡¦ç†
# ============================
def process_audio_and_generate_reply(audio_path):
    user_text = transcribe_audio(audio_path)
    print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_text}")

    memory_result = handle_memory_command(user_text)
    if memory_result:
        print(f"ğŸ§  {memory_result}")
        return synthesize_voice(memory_result)

    if user_text.endswith("ã§æ¤œç´¢ã—ã¦"):
        query = user_text.replace("ã§æ¤œç´¢ã—ã¦", "").strip()
        search_result = google_search_and_summarize(query)
        print(f"ğŸ” {search_result}")
        return synthesize_voice(search_result)

    reply = get_gemini_reply(user_text)
    print(f"ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {reply}")
    return synthesize_voice(reply)

# ============================
# ğŸ§ éŸ³å£°éŒ²éŸ³ï¼ˆF2ã§é–‹å§‹ãƒ»åœæ­¢ï¼‰
# ============================
THRESHOLD_START = 0.02
THRESHOLD_STOP = 0.01
SILENCE_DURATION = 1.0
SAMPLE_RATE = 44100

def smart_record(max_duration=8):
    print("ğŸ™ï¸ éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã‚ˆï¼ˆF2ã§çµ‚äº†ï¼‰")
    buffer = []
    is_recording = False
    silence_start = None
    stop_requested = False

    def monitor_stop_key():
        nonlocal stop_requested
        while True:
            if keyboard.is_pressed("F2"):
                stop_requested = True
                break
            time.sleep(0.1)

    threading.Thread(target=monitor_stop_key, daemon=True).start()

    def callback(indata, frames, time_info, status):
        nonlocal is_recording, silence_start, buffer
        volume = np.linalg.norm(indata)
        if not is_recording and volume > THRESHOLD_START:
            is_recording = True
            buffer.append(indata.copy())
        elif is_recording:
            buffer.append(indata.copy())
            if volume < THRESHOLD_STOP:
                if silence_start is None:
                    silence_start = time.time()
                elif time.time() - silence_start > SILENCE_DURATION:
                    print("ğŸ”‡ ç„¡éŸ³ã§åœæ­¢")
                    raise sd.CallbackStop()
            else:
                silence_start = None
        if stop_requested:
            print("ğŸ›‘ æ‰‹å‹•ã§åœæ­¢")
            raise sd.CallbackStop()

    try:
        with sd.InputStream(callback=callback, samplerate=SAMPLE_RATE, channels=1):
            sd.sleep(int(max_duration * 1000))
    except sd.CallbackStop:
        pass

    if not buffer:
        print("âš ï¸ éŸ³å£°ãŒéŒ²éŸ³ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return None

    audio_data = np.concatenate(buffer, axis=0)
    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    sf.write(tmp_file.name, audio_data, SAMPLE_RATE)
    return tmp_file.name

# ============================
# ğŸŒ Googleæ¤œç´¢ã¨sumyã«ã‚ˆã‚‹è¦ç´„ï¼ˆãƒ€ãƒŸãƒ¼HTMLä½¿ç”¨ï¼‰
# ============================
from sumy.parsers.html import HtmlParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from sumy.nlp.stemmers import Stemmer
from sumy.utils import get_stop_words

def google_search_and_summarize(query, num_sentences=2):
    """
    ä¸ãˆã‚‰ã‚ŒãŸã‚¯ã‚¨ãƒªã§Googleæ¤œç´¢ã‚’è¡Œã„ï¼ˆãƒ€ãƒŸãƒ¼HTMLã‚’ä½¿ç”¨ï¼‰ã€sumyã§è¦ç´„ã™ã‚‹ã€‚

    Args:
        query (str): æ¤œç´¢ã‚¯ã‚¨ãƒªã€‚
        num_sentences (int): è¦ç´„ã™ã‚‹æ–‡ã®æ•°ã€‚

    Returns:
        str: æ¤œç´¢çµæœã®è¦ç´„ã€‚
    """
    print(f"ğŸ” '{query}' ã§æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€sumyã§è¦ç´„ã—ã¾ã™...")
    # ã“ã“ã«å®Ÿéš›ã®Googleæ¤œç´¢ã¨HTMLå–å¾—ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒå…¥ã‚Šã¾ã™
    # ãƒ€ãƒŸãƒ¼ã®HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    dummy_html = """
    <html>
    <head><title>ãƒ€ãƒŸãƒ¼æ¤œç´¢çµæœ</title></head>
    <body>
        <p>ã“ã‚Œã¯ã‚¯ã‚¨ãƒª '{query}' ã«é–¢é€£ã™ã‚‹æœ€åˆã®ãƒ€ãƒŸãƒ¼ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã™ã€‚é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚</p>
        <p>ã“ã¡ã‚‰ã¯2ç•ªç›®ã®æ®µè½ã§ã™ã€‚æœ€åˆã®æ®µè½ã‚’è£œè¶³ã™ã‚‹è©³ç´°ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚</p>
        <p>3ç•ªç›®ã®æ®µè½ã§ã¯ã€å°‘ã—ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰ã®æƒ…å ±ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‚é‡è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚</p>
        <p>æœ€å¾Œã«ã€çµè«–ã¨ãªã‚‹4ç•ªç›®ã®æ®µè½ã§ã™ã€‚å…¨ä½“ã®è¦ç‚¹ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚</p>
    </body>
    </html>
    """

    try:
        parser = HtmlParser.from_string(dummy_html, "dummy_url", Tokenizer("japanese"))
        stemmer = Stemmer("japanese")
        summarizer = LsaSummarizer(stemmer)
        summarizer.stop_words = get_stop_words("ja")

        summary = summarizer(parser.document, num_sentences)
        summary_text = " ".join([str(sentence) for sentence in summary])
        return f"'{query}' ã«é–¢ã™ã‚‹æ¤œç´¢çµæœã®è¦ç´„ã§ã™ã€‚\n{summary_text}"

    except Exception as e:
        return f"âš ï¸ sumyã«ã‚ˆã‚‹è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
    
# ============================
# ğŸ›ï¸ å¿œç­”å‡¦ç†ãƒ¡ã‚¤ãƒ³
# ============================
def process_audio_and_generate_reply(audio_path):
    user_text = transcribe_audio(audio_path)
    print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_text}")

    # è¨˜æ†¶æ“ä½œ
    memory_result = handle_memory_command(user_text)
    if memory_result:
        print(f"ğŸ§  {memory_result}")
        return synthesize_voice(memory_result)

    # æ¤œç´¢ã‚³ãƒãƒ³ãƒ‰
    if user_text.endswith("ã§æ¤œç´¢ã—ã¦"):
        query = user_text.replace("ã§æ¤œç´¢ã—ã¦", "").strip()
        search_result = google_search_and_summarize(query)
        print(f"ğŸ” {search_result}")
        return synthesize_voice(search_result)

    # é€šå¸¸å¿œç­”ï¼ˆGeminiï¼‰
    reply = get_gemini_reply(user_text)
    print(f"ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {reply}")
    return synthesize_voice(reply)

# ============================
# ğŸ”´ ESCã‚­ãƒ¼ã§ã‚¢ãƒ—ãƒªçµ‚äº†
# ============================
def monitor_keys():
    global is_running
    while is_running:
        if keyboard.is_pressed("esc"):
            is_running = False
            print("ğŸ‘‹ ESCã§çµ‚äº†ã™ã‚‹ã‚ˆ")
        time.sleep(0.1)

# ============================
# ğŸš€ ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
# ============================
def main():
    global is_running
    is_running = True
    print("ğŸ” F2ã§éŒ²éŸ³ â†’ Geminiå¿œç­” â†’ AIVISéŸ³å£°å‡ºåŠ›ï½œESCã§çµ‚äº†")

    threading.Thread(target=monitor_keys, daemon=True).start()

    while is_running:
        if keyboard.is_pressed("F2"):
            time.sleep(0.2)
            try:
                audio_path = smart_record()
                if not audio_path or not is_running:
                    continue

                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(process_audio_and_generate_reply, audio_path)
                    voice_path = future.result()

                play_voice(voice_path)
            except Exception as e:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")

if __name__ == "__main__":
    main()

