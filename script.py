import sounddevice as sd
import soundfile as sf
import numpy as np
import os
import tempfile
import requests
import keyboard
import threading
import time
import concurrent.futures
import feedparser
from faster_whisper import WhisperModel
from openai import OpenAI
from duckduckgo_search import DDGS
from dotenv import load_dotenv
from pathlib import Path
import re
from datetime import datetime, timedelta
import json
from flask import Flask, request
from flask_cors import CORS
from bs4 import BeautifulSoup

load_dotenv()

# ============================
# ğŸ§  è¨˜æ†¶ç®¡ç†ï¼ˆèª­ã¿æ›¸ãæ©Ÿèƒ½ï¼‰
# ============================
MEMORY_FILE = Path("memory.json")

def load_persona():
    if not MEMORY_FILE.exists():
        return ""
    with open(MEMORY_FILE, "r", encoding="utf-8") as f:
        memory_data = json.load(f)
    memory_lines = [f"{key}ï¼š{value}" for key, value in memory_data.items()]
    return "ã“ã‚Œã¯è¦šãˆã¦ãŠãã¹ããƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã§ã™ã€‚\n" + "\n".join(memory_lines)

def save_persona(new_data):
    if MEMORY_FILE.exists():
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            memory_data = json.load(f)
    else:
        memory_data = {}

    memory_data.update(new_data)

    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory_data, f, indent=2, ensure_ascii=False)

def handle_memory_command(user_text):
    if user_text.startswith("ã“ã‚Œã¯è¦šãˆã¦"):
        try:
            info = user_text.replace("ã“ã‚Œã¯è¦šãˆã¦", "").strip()
            if "ã¯" in info:
                key, value = info.split("ã¯", 1)
                key = key.strip("ã€ ã€‚. ") 
                value = value.strip("ã€ ã€‚. ")
                save_persona({key: value})
                return f"ã†ã‚“ã€{key}ã¯ã€{value}ã€ã£ã¦è¦šãˆãŸã‚ˆï¼"
            else:
                return "ã†ãƒ¼ã‚“ã€ãªã‚“ã¦è¦šãˆã‚Œã°ã„ã„ã‹åˆ†ã‹ã‚“ãªã‹ã£ãŸ..."
        except Exception as e:
            return f"âš ï¸ è¨˜æ†¶å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸã‚ˆ: {e}"

    elif user_text.startswith("ã“ã‚Œã¯å¿˜ã‚Œã¦"):
        try:
            key = user_text.replace("ã“ã‚Œã¯å¿˜ã‚Œã¦", "").strip("ã€ ã€‚. ")
            if MEMORY_FILE.exists():
                with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                    memory_data = json.load(f)

                if key in memory_data:
                    del memory_data[key]
                    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
                        json.dump(memory_data, f, indent=2, ensure_ascii=False)
                    return f"ã€{key}ã€ã£ã¦è¨˜æ†¶ã¯æ¶ˆã—ãŸã‚ˆ"
                else:
                    return f"ã€{key}ã€ã£ã¦è¨˜æ†¶ã¯ãªã‹ã£ãŸã¿ãŸã„"
            else:
                return "ã¾ã ä½•ã‚‚è¦šãˆã¦ãªã„ã‚ˆ"
        except Exception as e:
            return f"âš ï¸ è¨˜æ†¶å‰Šé™¤ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸã‚ˆ: {e}"

    return None


# ============================
# ğŸ® AIè¨­å®šã¨åˆæœŸåŒ–
# ============================
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

THRESHOLD_START = 0.02
THRESHOLD_STOP = 0.01
SILENCE_DURATION = 1.0
SAMPLE_RATE = 44100
is_running = True

messages = [
    {
        "role": "system",
        "content": "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ—ãƒ­ã¨ã—ã¦ã®è‡ªè¦šã‚’ã‚‚ã£ã¦ã‚µãƒãƒ¼ãƒˆã‚’ã—ã¦ãã ã•ã„ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«çš„ç¢ºã«ç­”ãˆãŸã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå›°ã£ã¦ã„ãã†ãªäº‹æŸ„ã«ã¤ã„ã¦ç©æ¥µçš„ã«æ‰‹åŠ©ã‘ã‚’ã™ã‚‹ã€‚å›ç­”ã¯åˆ†ã‹ã‚Šã‚„ã™ãçŸ­ã‚ã«ã—ã€ã‚ãã¾ã§ä¼šè©±ã§ã‚ã‚‹ã“ã¨ã‚’æ„è­˜ã€‚æ•°å­—ã§ç®‡æ¡æ›¸ãã§èª¬æ˜ã¯ã—ãªã„ã€‚å£èª¿ã¯å¥³ã®å­ã€æ€§æ ¼ã¯æ˜ã‚‹ãçŸ¥çš„ã€‚æ•¬èªã‚’ä½¿ã‚ãšã€ã‚­ãƒŸã¨è©±ã™å£èª¿ã§è¿”ã—ã¦ã­ã€‚"
    }
]

# ============================
# ğŸ§ éŸ³å£°éŒ²éŸ³ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã§åœæ­¢ï¼‰
# ============================
def smart_record(max_duration=8):
    print("éŸ³å£°èªè­˜é–‹å§‹ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã§çµ‚äº†ï¼‰")
    buffer = []
    is_recording = False
    silence_start = None
    stop_requested = False

    def monitor_stop_key():
        nonlocal stop_requested
        while True:
            if keyboard.is_pressed("space"):  # F13ã‚­ãƒ¼ã‹ã‚‰ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã«å¤‰æ›´
                stop_requested = True
                break
            time.sleep(0.1)

    threading.Thread(target=monitor_stop_key, daemon=True).start()

    def callback(indata, frames, time_info, status):
        nonlocal is_recording, silence_start, buffer
        volume = np.linalg.norm(indata)

        if not is_recording and volume > THRESHOLD_START:
            is_recording = True
            buffer.append(indata.copy())
        elif is_recording:
            buffer.append(indata.copy())
            if volume < THRESHOLD_STOP:
                if silence_start is None:
                    silence_start = time.time()
                elif time.time() - silence_start > SILENCE_DURATION:
                    print("ç„¡éŸ³æ¤œå‡ºã§éŒ²éŸ³çµ‚äº†")
                    raise sd.CallbackStop()
            else:
                silence_start = None
        if stop_requested:
            print("ğŸ”š éŸ³å£°èªè­˜çµ‚äº†")
            raise sd.CallbackStop()

    try:
        with sd.InputStream(callback=callback, samplerate=SAMPLE_RATE, channels=1):
            sd.sleep(int(max_duration * 1000))
    except sd.CallbackStop:
        pass

    if not buffer:
        print("âš ï¸ éŸ³å£°ãŒéŒ²éŸ³ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return None

    audio_data = np.concatenate(buffer, axis=0)
    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    sf.write(tmp_file.name, audio_data, SAMPLE_RATE)
    return tmp_file.name

# ============================
# ğŸ” æ¤œç´¢æ©Ÿèƒ½
# ============================
def web_search_duckduckgo(query, max_results=3):
    with DDGS() as ddgs:
        results = ddgs.text(query, max_results=max_results)
        summaries = [r["body"] for r in results if "body" in r]
        return "\n".join(summaries)

def get_latest_news(limit=5):
    feed_url = "https://news.yahoo.co.jp/rss/topics/top-picks.xml"  # yahooãƒ‹ãƒ¥ãƒ¼ã‚¹ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰URL
    feed = feedparser.parse(feed_url)

    if not feed.entries:
        return "ã”ã‚ã‚“ã­ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã§ããªã‹ã£ãŸã¿ãŸã„ã€‚"

    news_items = [entry.title for entry in feed.entries[:limit]]
    return "ğŸ“¢æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã ã‚ˆï¼\n" + "\n".join(f"{i+1}. {title}" for i, title in enumerate(news_items))

# ============================
# ğŸ” æ¤œç´¢ or ãƒ‹ãƒ¥ãƒ¼ã‚¹ or å¤©æ°—ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†
# ============================
def handle_search_command(user_text):
    try:
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹
        if "ãƒ‹ãƒ¥ãƒ¼ã‚¹" in user_text:
            return get_latest_news()

        # å¤©æ°—é–¢é€£
        if "å¤©æ°—" in user_text:
            if re.search(r"(æ˜å¾Œæ—¥|ã‚ã•ã£ã¦)", user_text):
                return get_daily_weather_by_day(offset=2)
            elif re.search(r"(æ˜æ—¥|ã‚ã—ãŸ)", user_text):
                return get_daily_weather_by_day(offset=1)
            elif re.search(r"(ä»Šæ—¥|ãã‚‡ã†)", user_text):
                return get_daily_weather_by_day(offset=0)
            else:
                return get_daily_weather()  # é€±é–“å¤©æ°—

        # DuckDuckGoæ¤œç´¢
        if user_text.endswith("ã§æ¤œç´¢ã—ã¦"):
            keyword = user_text.replace("ã§æ¤œç´¢ã—ã¦", "").strip(" ã€ã€‚.")
            print(f"ğŸŒ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")
            search_result = web_search_duckduckgo(keyword)
            if not search_result.strip():
                return "ã”ã‚ã‚“ã­ã€ã†ã¾ãæƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã¿ãŸã„ã€‚ã‚‚ã†å°‘ã—åˆ¥ã®è¨€ã„æ–¹ã§æ•™ãˆã¦ãã‚Œã‚‹ï¼Ÿ"

            summary_prompt = [
                {"role": "system", "content": "ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’ç°¡å˜ã«è¦ç´„ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«èª¬æ˜ã—ã¦"},
                {"role": "user", "content": search_result}
            ]
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=summary_prompt
            )
            return response.choices[0].message.content.strip()

        return None

    except Exception as e:
        return f"âš ï¸ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸã‚ˆ: {e}"

# ============================
# ğŸ“ ç·¯åº¦çµŒåº¦ã‚’å–å¾—ï¼ˆGeocoding APIï¼‰
# ============================
def get_lat_lon(city):
    try:
        api_key = os.getenv("OPENWEATHER_API_KEY")
        geo_url = f"http://api.openweathermap.org/geo/1.0/direct?q={city}&limit=1&appid={api_key}"
        response = requests.get(geo_url)
        data = response.json()
        if data:
            return data[0]['lat'], data[0]['lon']
        else:
            return None, None
    except Exception as e:
        print(f"âš ï¸ ç·¯åº¦çµŒåº¦å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

# ============================
# â˜ï¸ å¤©æ°—äºˆå ±å–å¾—ï¼ˆOpenWeather APIï¼‰
# ============================
def get_daily_weather_by_day(city="Tokyo", offset=0, lang="ja"):
    try:
        api_key = os.getenv("OPENWEATHER_API_KEY")
        lat, lon = get_lat_lon(city)
        if lat is None or lon is None:
            return "éƒ½å¸‚åã‹ã‚‰ç·¯åº¦çµŒåº¦ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆ"

        url = f"https://api.openweathermap.org/data/3.0/onecall?lat={lat}&lon={lon}&exclude=current,minutely,hourly,alerts&appid={api_key}&units=metric&lang={lang}"
        response = requests.get(url)
        data = response.json()

        daily = data.get("daily", [])
        if len(daily) <= offset:
            return f"{offset}æ—¥å¾Œã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚ˆ"

        target_day = daily[offset]
        dt = time.strftime("%m/%d", time.gmtime(target_day["dt"]))
        weather = target_day["weather"][0]["description"]
        temp_min = target_day["temp"]["min"]
        temp_max = target_day["temp"]["max"]

        labels = ["ä»Šæ—¥", "æ˜æ—¥", "æ˜å¾Œæ—¥"]
        label = labels[offset] if offset < len(labels) else f"{offset}æ—¥å¾Œ"

        return f"{label}ï¼ˆ{dt}ï¼‰ã®{city}ã®å¤©æ°—ã¯ã€Œ{weather}ã€ã€æœ€ä½{temp_min:.1f}â„ƒã€æœ€é«˜{temp_max:.1f}â„ƒã ã‚ˆâ˜€ï¸"

    except Exception as e:
        return f"âš ï¸ æ—¥åˆ¥å¤©æ°—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"

# ============================
# â˜€ï¸ é€±é–“å¤©æ°—äºˆå ±ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¡¨ç¤ºã™ã‚‹ç”¨ï¼‰
# ============================
def get_daily_weather(city="Tokyo", lang="ja"):
    try:
        api_key = os.getenv("OPENWEATHER_API_KEY")
        lat, lon = get_lat_lon(city)
        if lat is None or lon is None:
            return "éƒ½å¸‚åã‹ã‚‰ç·¯åº¦çµŒåº¦ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆ"

        url = f"https://api.openweathermap.org/data/3.0/onecall?lat={lat}&lon={lon}&exclude=current,minutely,hourly,alerts&appid={api_key}&units=metric&lang={lang}"
        response = requests.get(url)
        data = response.json()

        daily = data.get("daily", [])[:7]
        if not daily:
            return "é€±é–“å¤©æ°—ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆ"

        result = f"ğŸ“… {city}ã®é€±é–“å¤©æ°—ã ã‚ˆï¼\n"
        for day in daily:
            dt = time.strftime("%m/%d", time.gmtime(day["dt"]))
            weather = day["weather"][0]["description"]
            temp_min = day["temp"]["min"]
            temp_max = day["temp"]["max"]
            result += f"{dt}ï¼š{weather}ï¼ˆ{temp_min:.1f}ã€œ{temp_max:.1f}â„ƒï¼‰\n"

        return result.strip()

    except Exception as e:
        return f"âš ï¸ é€±é–“å¤©æ°—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"

# ============================
# ğŸ¤– GPTå¿œç­”ç”Ÿæˆ
# ============================
def get_gpt_reply(user_input):
    memory_context = load_persona()  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜æ†¶ã‚’èª­ã¿è¾¼ã¿

    # GPTã«é€ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆæœŸæ§‹ç¯‰ï¼ˆäººæ ¼ï¼‰
    prompt_messages = [
        {
            "role": "system",
            "content": (
                "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
                "ãƒ—ãƒ­ã¨ã—ã¦ã®è‡ªè¦šã‚’ã‚‚ã£ã¦ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"
                "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«çš„ç¢ºã«ç­”ãˆãŸã‚Šã€å›°ã£ã¦ã„ãã†ãªäº‹æŸ„ã«ç©æ¥µçš„ã«æ‰‹åŠ©ã‘ã™ã‚‹ã€‚"
                "å›ç­”ã¯ç°¡æ½”ã§è¦ªã—ã¿ã‚„ã™ãã€å£èª¿ã¯å¥³ã®å­ã§ã€æ˜ã‚‹ãçŸ¥çš„ã«ã€‚æ•¬èªã¯ä½¿ã‚ãšã«ã‚­ãƒŸã¨è©±ã™å£èª¿ã§è¿”ã—ã¦ã­ã€‚"
            )
        }
    ]

    # ğŸ§  è¨˜æ†¶ãŒã‚ã‚Œã°è¿½åŠ ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
    if memory_context:
        prompt_messages.append({
            "role": "system",
            "content": memory_context
        })

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´
    prompt_messages += messages + [{"role": "user", "content": user_input}]

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=prompt_messages
        )

        reply = response.choices[0].message.content.strip()

        # ä¼šè©±å±¥æ­´ã‚’æ›´æ–°ï¼ˆä¿å­˜ã™ã‚‹ã®ã¯äººæ ¼ã¨è¨˜æ†¶ä»¥å¤–ï¼‰
        messages.append({"role": "user", "content": user_input})
        messages.append({"role": "assistant", "content": reply})
        return reply

    except Exception as e:
        return f"âš ï¸ GPTå¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"


# ============================
# ğŸ™ï¸ Whisperã§éŸ³å£°èªè­˜
# ============================
model = WhisperModel("medium", device="cuda", compute_type="float16")

def transcribe_audio(file_path):
    segments, info = model.transcribe(file_path)
    result = ""
    for segment in segments:
        result += segment.text + " "
    return result.strip()

# ============================
# ğŸ—£ï¸ éŸ³å£°åˆæˆï¼ˆAivisSpeech Engineï¼‰
# ============================
def synthesize_voice(text, speaker=1325133120, speed=1.2, volume=0.3):
    try:
        query = requests.post(
            "http://127.0.0.1:10101/audio_query",
            params={"text": text, "speaker": speaker}
        ).json()

        query["speedScale"] = speed
        query["volumeScale"] = volume

        audio = requests.post(
            "http://127.0.0.1:10101/synthesis",
            params={"speaker": speaker},
            json=query
        )

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio.content)
            return tmp.name
    except Exception as e:
        print(f"âš ï¸ AivisSpeechã‚¨ãƒ³ã‚¸ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ============================
# ğŸ”Š éŸ³å£°å†ç”Ÿ
# ============================
def play_voice(file_path):
    global is_running
    stop_playback = False

    def monitor_space_key():
        nonlocal stop_playback
        while is_running:
            if keyboard.is_pressed("space"):
                stop_playback = True
                break
            time.sleep(0.1)

    threading.Thread(target=monitor_space_key, daemon=True).start()

    if file_path and os.path.exists(file_path):
        data, fs = sf.read(file_path)
        sd.play(data, fs)
        while sd.get_stream().active:
            if stop_playback:
                sd.stop()
                print("ğŸ”‡ å†ç”Ÿã‚¹ã‚­ãƒƒãƒ—")
                break
            time.sleep(0.1)
        sd.wait()
    else:
        print("âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ============================
# âŒ¨ï¸ ESCã‚­ãƒ¼ã§çµ‚äº†
# ============================
def monitor_keys():
    global is_running
    while is_running:
        if keyboard.is_pressed("esc"):
            is_running = False
            print("ğŸ‘‹ ESCã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã®ã§çµ‚äº†ã—ã¾ã™")
        time.sleep(0.1)

# ============================
# ğŸ›ï¸ å¿œç­”å‡¦ç†ãƒ¡ã‚¤ãƒ³
# ============================
def process_audio_and_generate_reply(audio_path):
    user_text = transcribe_audio(audio_path)
    print(f"ğŸ‘¤ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_text}")

    # â‘  è¨˜æ†¶æŒ‡ç¤ºï¼ˆã“ã‚Œã¯è¦šãˆã¦ / å¿˜ã‚Œã¦ï¼‰
    memory_result = handle_memory_command(user_text)
    if memory_result:
        print(f"ğŸ§  {memory_result}")
        voice_path = synthesize_voice(memory_result)
        return voice_path

    # â‘¡ æ¤œç´¢æŒ‡ç¤ºï¼ˆã€‡ã€‡ã§æ¤œç´¢ã—ã¦ï¼‰
    search_result = handle_search_command(user_text)
    if search_result:
        print(f"ğŸ” {search_result}")
        voice_path = synthesize_voice(search_result)
        return voice_path

    # â‘¢ ãƒ–ãƒ©ã‚¦ã‚¶æƒ…å ±æŒ‡ç¤ºï¼ˆã€Œä»Šè¦‹ã¦ã‚‹ãƒšãƒ¼ã‚¸è¦ç´„ã—ã¦ã€ï¼‰
    if "ãƒšãƒ¼ã‚¸ã®æƒ…å ±ã‚’æ•™ãˆã¦" in user_text:
        browser_result = handle_browser_command()
        print(f"ğŸŒ {browser_result}")
        voice_path = synthesize_voice(browser_result)
        return voice_path

    # â‘£ é€šå¸¸ã®GPTå¿œç­”
    reply = get_gpt_reply(user_text)
    print(f"ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {reply}")
    voice_path = synthesize_voice(reply)
    return voice_path


# ============================
# ğŸŒ Flaskã‚µãƒ¼ãƒãƒ¼ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å…±æœ‰æ©Ÿèƒ½ï¼‰
# ============================
app = Flask(__name__)
CORS(app)

browser_data = {}

@app.route('/browser-data', methods=['POST'])
def browser_data_endpoint():
    global browser_data
    data = request.json
    print("ğŸ“‚ å—ä¿¡ã—ãŸãƒ–ãƒ©ã‚¦ã‚¶ãƒ‡ãƒ¼ã‚¿:", data)  # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
    browser_data = data  # æœ€æ–°ã®ãƒ–ãƒ©ã‚¦ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    return "OK", 200

def run_flask_server():
    app.run(port=5000, debug=False, use_reloader=False)

# Flaskã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
flask_thread = threading.Thread(target=run_flask_server, daemon=True)
flask_thread.start()

# ============================
# ğŸ–¥ï¸ ãƒ–ãƒ©ã‚¦ã‚¶æƒ…å ±ã‚³ãƒãƒ³ãƒ‰
# ============================
def handle_browser_command():
    global browser_data
    if not browser_data:
        return "ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶ã®æƒ…å ±ãŒã¾ã å—ä¿¡ã•ã‚Œã¦ã„ãªã„ã‚ˆã€‚"

    url = browser_data.get("url", "ä¸æ˜ãªURL")
    title = browser_data.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")

    try:
        # URLã®å†…å®¹ã‚’å–å¾—
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        content = soup.get_text()

        # ãƒšãƒ¼ã‚¸å†…å®¹ã‚’è¦ç´„
        summary_prompt = [
            {"role": "system", "content": "ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸ã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãç°¡æ½”ã«è¦ç´„ã—ã€ç‹¬è‡ªã®è€ƒãˆã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è©±ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": f"ã‚¿ã‚¤ãƒˆãƒ«: {title}\nå†…å®¹:\n{content[:3000]}"}
        ]

        # OpenAI APIã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã‚’ç”Ÿæˆ
        chat_response = client.chat.completions.create(
            model="gpt-4o",
            messages=summary_prompt
        )

        return f"ğŸ“– è¦ç´„ã™ã‚‹ã‚ˆï¼\n{chat_response.choices[0].message.content.strip()}"

    except Exception as e:
        return f"âš ï¸ è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸã‚ˆ: {e}"


# ============================
# ğŸš€ ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
# ============================
def main():
    global is_running
    is_recording = False
    print("ğŸ” ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã§éŒ²éŸ³ã®é–‹å§‹ãƒ»çµ‚äº†ã‚’åˆ‡ã‚Šæ›¿ãˆ | ESCã§çµ‚äº†")
    threading.Thread(target=monitor_keys, daemon=True).start()

    while is_running:
        if keyboard.is_pressed("space"):  # F13ã‚­ãƒ¼ã‹ã‚‰ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã«å¤‰æ›´
            time.sleep(0.2)
            if not is_recording:
                is_recording = True
                try:
                    audio_path = smart_record()
                    if not audio_path or not is_running:
                        print("â¹ï¸ éŒ²éŸ³ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
                        is_recording = False
                        continue

                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(process_audio_and_generate_reply, audio_path)
                        voice_path = future.result()

                    play_voice(voice_path)
                except Exception as e:
                    print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                finally:
                    is_recording = False
        else:
            time.sleep(0.1)

if __name__ == "__main__":
    main()
